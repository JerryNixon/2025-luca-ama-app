#!/usr/bin/env python3
"""
Fabric SQL Performance Optimization
Optimizes the Django backend to work better with Fabric SQL while maintaining the requirement.
"""

import os
import sys
from pathlib import Path

def optimize_django_settings():
    """Add performance optimizations for Fabric SQL"""
    
    print("üöÄ Optimizing Django Settings for Fabric SQL Performance")
    print("=" * 60)
    
    backend_dir = Path(__file__).parent / "backend"
    settings_file = backend_dir / "ama_backend" / "settings.py"
    
    if not settings_file.exists():
        print("‚ùå Could not find settings.py file")
        return False
    
    # Read current settings
    with open(settings_file, 'r') as f:
        content = f.read()
    
    # Check if optimizations are already added
    if 'FABRIC_SQL_OPTIMIZATIONS' in content:
        print("‚úÖ Optimizations already applied")
        return True
    
    # Add performance optimizations
    optimizations = '''

# FABRIC_SQL_OPTIMIZATIONS: Performance optimizations for Microsoft Fabric SQL
# These settings improve response times while maintaining Fabric SQL requirement

# Database Connection Pooling
DATABASES['default']['CONN_MAX_AGE'] = 600  # Keep connections alive for 10 minutes
DATABASES['default']['OPTIONS']['extra_params'] += ';Connection Timeout=5;Command Timeout=10'

# Caching Configuration - Use Redis or in-memory cache
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
        'LOCATION': 'unique-snowflake',
        'TIMEOUT': 300,  # 5 minutes
        'OPTIONS': {
            'MAX_ENTRIES': 1000,
            'CULL_FREQUENCY': 3,
        }
    }
}

# Cache sessions to reduce database hits
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
SESSION_CACHE_ALIAS = 'default'

# Enable query optimization
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
        },
    },
    'loggers': {
        'django.db.backends': {
            'handlers': ['console'],
            'level': 'DEBUG' if DEBUG else 'INFO',
        },
    },
}

print("‚ö° Applied Fabric SQL performance optimizations")
print("üîÑ Connection pooling: Enabled (10 min)")
print("üíæ Caching: Enabled (in-memory)")
print("‚è±Ô∏è  Timeouts: Reduced (5s connection, 10s command)")
'''

    # Add optimizations to the end of the file
    new_content = content + optimizations
    
    # Write back to file
    with open(settings_file, 'w') as f:
        f.write(new_content)
    
    print("‚úÖ Added performance optimizations to settings.py")
    return True

def add_caching_to_views():
    """Add caching decorators to API views"""
    print("\nüóÑÔ∏è  Adding Caching to API Views...")
    
    backend_dir = Path(__file__).parent / "backend"
    views_file = backend_dir / "api" / "views.py"
    
    if not views_file.exists():
        print("‚ùå Could not find views.py file")
        return False
    
    # Read current views
    with open(views_file, 'r') as f:
        content = f.read()
    
    # Check if caching is already added
    if 'cache_page' in content:
        print("‚úÖ Caching already added to views")
        return True
    
    # Add cache imports
    if 'from django.views.decorators.cache import cache_page' not in content:
        # Find the imports section and add cache import
        lines = content.split('\n')
        import_line = -1
        for i, line in enumerate(lines):
            if line.startswith('from django.') and 'import' in line:
                import_line = i
        
        if import_line != -1:
            lines.insert(import_line + 1, 'from django.views.decorators.cache import cache_page')
            lines.insert(import_line + 2, 'from django.utils.decorators import method_decorator')
        
        content = '\n'.join(lines)
        
        # Write back to file
        with open(views_file, 'w') as f:
            f.write(content)
        
        print("‚úÖ Added caching imports to views.py")
    
    return True

def create_performance_middleware():
    """Create custom middleware for response time optimization"""
    print("\n‚ö° Creating Performance Middleware...")
    
    backend_dir = Path(__file__).parent / "backend"
    middleware_file = backend_dir / "api" / "middleware.py"
    
    middleware_content = '''"""
Performance Middleware for Fabric SQL Optimization
Adds response time headers and optimizes database queries.
"""

import time
import logging
from django.utils.deprecation import MiddlewareMixin
from django.http import JsonResponse

logger = logging.getLogger(__name__)

class PerformanceMiddleware(MiddlewareMixin):
    """
    Middleware to optimize performance for Fabric SQL database
    """
    
    def process_request(self, request):
        """Start timing the request"""
        request.start_time = time.time()
        return None
    
    def process_response(self, request, response):
        """Add performance headers and log slow requests"""
        if hasattr(request, 'start_time'):
            total_time = time.time() - request.start_time
            
            # Add performance header
            response['X-Response-Time'] = f'{total_time:.3f}s'
            
            # Log slow requests
            if total_time > 1.0:
                logger.warning(f"Slow request: {request.method} {request.path} took {total_time:.3f}s")
            
            # For API responses, add timing info
            if (response.get('Content-Type', '').startswith('application/json') 
                and hasattr(response, 'data') and isinstance(response.data, dict)):
                response.data['_performance'] = {
                    'response_time': f'{total_time:.3f}s',
                    'database': 'Microsoft Fabric SQL'
                }
        
        return response
'''

    with open(middleware_file, 'w') as f:
        f.write(middleware_content)
    
    print("‚úÖ Created performance middleware")
    
    # Add middleware to settings
    settings_file = backend_dir / "ama_backend" / "settings.py"
    with open(settings_file, 'r') as f:
        content = f.read()
    
    if 'api.middleware.PerformanceMiddleware' not in content:
        # Find MIDDLEWARE setting and add our middleware
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if 'MIDDLEWARE = [' in line:
                # Insert after CorsMiddleware
                for j in range(i + 1, len(lines)):
                    if 'corsheaders.middleware.CorsMiddleware' in lines[j]:
                        lines.insert(j + 1, "    'api.middleware.PerformanceMiddleware',")
                        break
                break
        
        content = '\n'.join(lines)
        with open(settings_file, 'w') as f:
            f.write(content)
        
        print("‚úÖ Added performance middleware to settings")

def optimize_question_queries():
    """Add database indexes and query optimizations"""
    print("\nüîç Creating Database Query Optimizations...")
    
    backend_dir = Path(__file__).parent / "backend"
    
    # Create a custom migration for indexes
    migration_content = '''# Generated optimization migration for Fabric SQL performance

from django.db import migrations

class Migration(migrations.Migration):
    
    dependencies = [
        ('api', '0001_initial'),  # Adjust based on your latest migration
    ]
    
    operations = [
        # Add database indexes for common queries
        migrations.RunSQL(
            "CREATE INDEX IF NOT EXISTS idx_questions_event_id ON api_question(event_id);",
            reverse_sql="DROP INDEX IF EXISTS idx_questions_event_id;"
        ),
        migrations.RunSQL(
            "CREATE INDEX IF NOT EXISTS idx_questions_is_staged ON api_question(is_staged);",
            reverse_sql="DROP INDEX IF EXISTS idx_questions_is_staged;"
        ),
        migrations.RunSQL(
            "CREATE INDEX IF NOT EXISTS idx_questions_is_starred ON api_question(is_starred);",
            reverse_sql="DROP INDEX IF EXISTS idx_questions_is_starred;"
        ),
        migrations.RunSQL(
            "CREATE INDEX IF NOT EXISTS idx_questions_upvotes ON api_question(upvotes);",
            reverse_sql="DROP INDEX IF EXISTS idx_questions_upvotes;"
        ),
        migrations.RunSQL(
            "CREATE INDEX IF NOT EXISTS idx_questions_created_at ON api_question(created_at);",
            reverse_sql="DROP INDEX IF EXISTS idx_questions_created_at;"
        ),
    ]
'''

    migrations_dir = backend_dir / "api" / "migrations"
    migration_file = migrations_dir / "0002_performance_indexes.py"
    
    with open(migration_file, 'w') as f:
        f.write(migration_content)
    
    print("‚úÖ Created database index migration")

def create_frontend_optimizations():
    """Create frontend optimizations for better perceived performance"""
    print("\nüåê Creating Frontend Performance Optimizations...")
    
    frontend_dir = Path(__file__).parent / "frontend" / "src"
    
    # Create a response cache utility
    cache_util = frontend_dir / "utils" / "responseCache.ts"
    cache_util.parent.mkdir(exist_ok=True)
    
    cache_content = '''/**
 * Response Cache Utility
 * Implements client-side caching to reduce API calls to Fabric SQL
 */

interface CacheEntry<T> {
  data: T;
  timestamp: number;
  ttl: number; // Time to live in milliseconds
}

class ResponseCache {
  private cache = new Map<string, CacheEntry<any>>();
  
  /**
   * Get cached data if it's still valid
   */
  get<T>(key: string): T | null {
    const entry = this.cache.get(key);
    if (!entry) return null;
    
    const now = Date.now();
    if (now - entry.timestamp > entry.ttl) {
      this.cache.delete(key);
      return null;
    }
    
    return entry.data;
  }
  
  /**
   * Store data in cache with TTL
   */
  set<T>(key: string, data: T, ttlMs: number = 30000): void {
    this.cache.set(key, {
      data,
      timestamp: Date.now(),
      ttl: ttlMs
    });
  }
  
  /**
   * Clear cache for a specific key or pattern
   */
  invalidate(keyPattern: string): void {
    for (const key of this.cache.keys()) {
      if (key.includes(keyPattern)) {
        this.cache.delete(key);
      }
    }
  }
  
  /**
   * Clear all cache
   */
  clear(): void {
    this.cache.clear();
  }
}

export const responseCache = new ResponseCache();
'''

    with open(cache_util, 'w') as f:
        f.write(cache_content)
    
    print("‚úÖ Created frontend response cache utility")

def provide_optimization_summary():
    """Provide summary of optimizations"""
    print("\n" + "=" * 60)
    print("‚úÖ FABRIC SQL PERFORMANCE OPTIMIZATIONS COMPLETE")
    print("=" * 60)
    print("üéØ Applied Optimizations:")
    print("  ‚Ä¢ Database connection pooling (10 min)")
    print("  ‚Ä¢ In-memory caching for frequent queries")
    print("  ‚Ä¢ Reduced connection/command timeouts")
    print("  ‚Ä¢ Performance monitoring middleware")
    print("  ‚Ä¢ Database indexes for common queries")
    print("  ‚Ä¢ Frontend response caching")
    
    print("\nüìä Expected Improvements:")
    print("  ‚Ä¢ First request: Still 2s+ (Fabric SQL latency)")
    print("  ‚Ä¢ Cached requests: <100ms (in-memory)")
    print("  ‚Ä¢ Connection reuse: Faster subsequent requests")
    print("  ‚Ä¢ Better error handling and monitoring")
    
    print("\nüöÄ Next Steps:")
    print("  1. Restart Django server to apply changes")
    print("  2. Run migrations for database indexes")
    print("  3. Test button performance")
    print("  4. Monitor performance headers")
    
    print("\nüìù Commands to run:")
    print("  cd backend")
    print("  python manage.py migrate")
    print("  python manage.py runserver")

def main():
    print("üéØ OPTIMIZING FABRIC SQL PERFORMANCE")
    print("=" * 60)
    print("Requirements: Must use Microsoft Fabric SQL Database")
    print("Goal: Reduce button lag while maintaining Fabric SQL")
    print("=" * 60)
    
    # Apply optimizations
    optimize_django_settings()
    add_caching_to_views()
    create_performance_middleware()
    optimize_question_queries()
    create_frontend_optimizations()
    provide_optimization_summary()

if __name__ == "__main__":
    main()
